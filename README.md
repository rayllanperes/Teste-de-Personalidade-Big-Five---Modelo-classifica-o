# Teste de Personalidade Big Five üë•


![capa](https://github.com/user-attachments/assets/01a37342-1f1b-46df-b26b-932b73a1c48c)



### ‚óæContexto:
Os Cinco Grandes tra√ßos de personalidade, tamb√©m conhecidos como modelo dos cinco fatores (FFM) e modelo OCEAN, s√£o uma taxonomia, ou agrupamento, para tra√ßos de personalidade. Quando a an√°lise fatorial (uma t√©cnica estat√≠stica) √© aplicada a dados de pesquisa de personalidade, algumas palavras usadas para descrever aspectos da personalidade s√£o frequentemente aplicadas √† mesma pessoa. Por exemplo, algu√©m descrito como consciencioso tem mais probabilidade de ser descrito como "sempre preparado" do que "bagunceiro". Esta teoria √© baseada, portanto, na associa√ß√£o entre palavras, mas n√£o em experimentos neuropsicol√≥gicos. Esta teoria usa descritores de linguagem comum e, portanto, sugere cinco dimens√µes amplas comumente usadas para descrever a personalidade e a psique humanas.

**O conjunto de dados**

Este conjunto de dados cont√©m 1.015.342 respostas de question√°rios coletadas on-line pela Open Psychometrics .

### ‚óæInstala√ß√£o das bibliotecas

Para desenvolvimento do projeto, foram utilizadas bibliotecas como **[pandas](https://pandas.pydata.org/)**, **[matplotlib](https://matplotlib.org/)**, **[scikit-learn](https://scikit-learn.org/)**, **[seaborn](https://seaborn.pydata.org/)** , **[plotly](https://plotly.com/python/)** , **[yellowbrick](https://www.scikit-yb.org/en/latest/)**, **[gradio](https://www.gradio.app/docs)**, **[os](https://docs.python.org/pt-br/3.13/library/os.html)** e **[io](https://docs.python.org/3/library/io.html)**.

Para trazermos algumas bibliotecas necess√°rias na cria√ß√£o do projeto, foi necess√°rio utilizar o comando **pip install** ou import√°-las com o comando **import** em uma c√©lula do Colab.

```
!pip install yellowbrick
!pip install gradio

import pandas as pd
import numpy as np

from sklearn.cluster import KMeans
from yellowbrick.cluster import KElbowVisualizer

import gradio as gr
import matplotlib.pyplot as plt
import seaborn as sns

import os
from io import open

```

### ‚óæAn√°lise Explorat√≥ria De Dados(AED):
Ap√≥s carregar o conjunto de dados IPIP-FFM, realizamos uma an√°lise explorat√≥ria para entender a estrutura dos dados e preparar o dataset para modelagem. O processo incluiu:

- **Carregamento dos Dados**: O dataset foi carregado a partir de um arquivo CSV utilizando Pandas.
- **Redu√ß√£o de Dimensionalidade**: Foram removidas colunas entre as posi√ß√µes 50 e 110, reduzindo o tamanho do conjunto de dados.
- **An√°lise de Distribui√ß√£o**: Foi analisada a contagem de valores da vari√°vel EXT1 para verificar a distribui√ß√£o dos dados.
- **Estat√≠sticas Descritivas**: Foram calculadas estat√≠sticas como m√©dia, mediana, desvio padr√£o e distribui√ß√£o dos dados num√©ricos usando .describe().
- **Tratamento de Dados**: Linhas com valores iguais a zero em todas as colunas foram removidas para garantir que apenas dados v√°lidos fossem considerados.
- **Amostragem**: Foi selecionada uma amostra de 5.000 registros para an√°lise posterior.
- **Agrupamento com K-Means**: Foi utilizado o m√©todo do Cotovelo (Elbow Method) para determinar o n√∫mero ideal de clusters para agrupamento dos dados, usando Yellowbrick para visualiza√ß√£o.

Essa an√°lise permitiu uma melhor compreens√£o da estrutura dos dados e serviu como base para a aplica√ß√£o de t√©cnicas de clusteriza√ß√£o no projeto. üöÄ

### O conjunto de dados:

Este conjunto de dados cont√©m 1.015.342 respostas de question√°rios coletadas on-line pela Open Psychometrics .

### ‚óæExecutando o teste.:

  ![Quantidade de grupos](https://github.com/user-attachments/assets/5aa2f374-0d8d-4cb7-8ada-6332c1e852ea)

<p align="left">
   Verificamos que o n√∫mero ideal para essa base de dados √© 5.
</p>



### ‚óæVisualizando as m√©dias por grupo:


![analise de grupos](https://github.com/user-attachments/assets/410fe5d1-8cd6-48f1-9b25-bb654479b421)


### ‚óæUtiliza√ß√£o:
Para usar este c√≥digo, siga estas etapas:

1. Instale as bibliotecas(depend√™ncias) necess√°rias listadas logo no in√≠cio;

2. Copie e cole o c√≥digo em um ambiente Python, como Jupyter Notebook ou um script Python;

3. Execute o c√≥digo para carregar o conjunto de dados, tratamentos, treinar os modelos e gerar m√©tricas de desempenho e visualiza√ß√µes;

4. Insira os par√¢metros desejados para realizar a previs√£o de vendas.

### ‚óæ Tecnologias Utilizadas: 
pandas, numpy, sklearn, yellowbrick, gradio, matplotlib, seaborn, os e io.

## Autor:

<img  src="https://github.com/user-attachments/assets/05d01cfe-fa21-445f-815f-a4e9c14851ba" width="80" alt="cognitiveclass.ai logo" align="left" />

### &nbsp;&nbsp;Rayllan Peres

<p>
&nbsp;&nbsp;Estudante De Ci√™ncia De Dados / Business Intelligence / Analista De Dados<br/>
&nbsp;&nbsp;LinkedIn: https://www.linkedin.com/in/rayllan-peres/<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;E-mail: rayllanperes@gmail.com<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Portif√≥lio de projetos em Data Science: https://github.com/rayllanperes
</p>